{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for getting & parsing RSS feeds\n",
    "import feedparser as fp\n",
    "import pandas as pd\n",
    "import html\n",
    "from nltk.tokenize import TreebankWordTokenizer,WhitespaceTokenizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import time\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The FeedCrawler class interfaces w/ feedparser to comb RSS feeds and store them in\n",
    "#the desired location/format.\n",
    "\n",
    "\n",
    "class NoMoreFeedError(Exception):\n",
    "    pass\n",
    "\n",
    "class FeedCrawler():\n",
    "    def __init__(self,podcast_df,foutloc,identifier=str(int(time.time()))):\n",
    "        self.foutloc = foutloc\n",
    "        self.podcast_df = podcast_df\n",
    "        self.counter = 0\n",
    "        self.feeds = []\n",
    "        self.feedctr = []\n",
    "        self.state = 'parsed'\n",
    "        self.filecounter = 0\n",
    "        self.identifier = identifier\n",
    "        \n",
    "    def getNcasts(self):\n",
    "        return self.podcast_df.shape[0]\n",
    "    \n",
    "    #gets the next n feeds in \n",
    "    def getFeed(self,n):\n",
    "        for i in range(0,n):\n",
    "            if(self.counter > self.podcast_df.shape[0]):\n",
    "                raise NoMoreFeedError\n",
    "            url = podcast_df.iloc[self.counter]['feedUrl']\n",
    "            self.feeds.append(self._feed_request(url))\n",
    "            self.counter += 1\n",
    "    \n",
    "    def parseFeeds(self):\n",
    "        parsed_feeds = []\n",
    "        for f in self.feeds:\n",
    "            try:\n",
    "                  parsed_feeds.append([[f[1]['entries'][k]['content'][0]['value'],\n",
    "                                             f[1]['entries'][k]['title'],\n",
    "                                             f[1]['entries'][k]['author']] \n",
    "                                             for k in range(0,len(f[1]['entries']))])\n",
    "                                      \n",
    "            except KeyError as e:\n",
    "                pass\n",
    "        self.feeds = parsed_feeds\n",
    "        self.state = 'parsed'\n",
    "        print('Parsed!')\n",
    "\n",
    "    def _saveFeeds(self):\n",
    "        print('Saving %d feeds...' % len(self.feeds))\n",
    "        with open(foutloc+'feeds_'+str(self.filecounter)+'_'+str(self.identifier)+'.pkl','wb') as fid:\n",
    "            pickle.dump(self.feeds,fid)\n",
    "            self.filecounter += 1\n",
    "    \n",
    "    def _saveProgress(self):\n",
    "        with open(foutloc+'progress.pkl','wb') as fid:\n",
    "            pickle.dump([self.identifier,self.filecounter,self.counter],fid)\n",
    "    \n",
    "    def save(self):\n",
    "        self._saveFeeds()\n",
    "        self._saveProgress()\n",
    "        self._resetFeeds()\n",
    "        \n",
    "    def loadcounters(self):\n",
    "        with open(foutloc+'progress.pkl','rb') as fid:\n",
    "            progress = pickle.load(fid)\n",
    "            self.identifier = progress[0]\n",
    "            self.filecounter = progress[1]\n",
    "            self.counter = progress[2]\n",
    "            \n",
    "    \n",
    "    def _resetFeeds(self):\n",
    "        self.feeds = []\n",
    "        self.state = 'raw'\n",
    "        \n",
    "    def resetCounter(self):\n",
    "        self.counter = 0\n",
    "        \n",
    "    @classmethod \n",
    "    def _feed_request(cls,url):\n",
    "        try:\n",
    "            return (url,fp.parse(url))\n",
    "        except:\n",
    "            print('Error on ' + url)\n",
    "            return (url,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in putative podcasts, turn it into a dataframe. \n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#load in itunes_request_db\n",
    "floc = '//Users/Jay/AnacondaProjects/plutarch/get_episodes/'\n",
    "with open(floc+'raw_itunes_requests.pkl','rb') as fid:\n",
    "    raw_itunes_requests = pickle.load(fid)\n",
    "    \n",
    "#turn everything into a pandas dataframe\n",
    "formatted_results = []\n",
    "bads = []\n",
    "cnames = ['']\n",
    "for rir in raw_itunes_requests:\n",
    "    for p in rir.json()['results']:\n",
    "        if(p['kind']=='podcast'):\n",
    "            formatted_results.append(p)\n",
    "\n",
    "podcast_df = pd.DataFrame(formatted_results)\n",
    "podcast_df = podcast_df.loc[podcast_df['feedUrl'].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crawl & scrape RSS feeds\n",
    "#We will visit every RSS feed and scrape all the episode data.\n",
    "import numpy as np\n",
    "import time\n",
    "import socket\n",
    "import feedparser as fp\n",
    "import requests\n",
    "\n",
    "MAX_REQUEST_DURATION = 10 #seconds\n",
    "socket.setdefaulttimeout(MAX_REQUEST_DURATION)\n",
    "\n",
    "step_size = 10#number of feeds to get/save at once\n",
    "foutloc = '/Users/Jay/AnacondaProjects/plutarch/get_episodes/preprocessed/'\n",
    "crawler = FeedCrawler(podcast_df,foutloc)\n",
    "\n",
    "try:\n",
    "    crawler.loadcounters()\n",
    "    print('initialized! counter = %d,filecounter = %d,id = %s' %\n",
    "          (crawler.counter,crawler.filecounter,crawler.identifier))\n",
    "except:\n",
    "    print(\"could not initialize\")\n",
    "    init = 0\n",
    "\n",
    "flag = 1\n",
    "while(flag):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        crawler.getFeed(step_size)\n",
    "        crawler.parseFeeds()\n",
    "        crawler.save()\n",
    "    except NoMoreFeedError as e:\n",
    "        flag = 0\n",
    "        print(\"Job's done!\")\n",
    "    stop_time = time.time()\n",
    "    duration = stop_time - start_time\n",
    "    print('Counter=%d/%d (duration=%.2f, step=%d)' % (crawler.counter,crawler.getNcasts(),duration,step_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save out the scraped RSS feeds.\n",
    "import pickle\n",
    "\n",
    "floc = '/Users/Jay/AnacondaProjects/plutarch/get_episodes/angie/'\n",
    "with open(floc+'feeds_0_1538436207.pkl','rb') as fid:\n",
    "    prog = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Peg Entwistle, Ghost of Hollywood',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'https://feeds.megaphone.fm/stuffyoumissedinhistoryclass',\n",
       "  'value': 'Peg Entwistle, Ghost of Hollywood'},\n",
       " 'summary': \"Her story is often told in a sort of sloppy shorthand: She went to Los Angeles to become an actress, failed, and then became desperate. But that isn’t a really accurate picture of Peg Entwistle at all.&nbsp;<br><br><br><br><br><br><br><br>Learn more about advertising on the HowStuffWorks podcasts at <a href='http://www.howstuffworks.com/advertisers.htm'>www.howstuffworks.com/advertisers.htm</a><br><br>And to learn about your ad choices when listening to podcasts, visit <a href='https://www.howstuffworks.com/privacy.htm#ad-choices'>https://www.howstuffworks.com/privacy.htm#ad-choices</a>\",\n",
       " 'summary_detail': {'type': 'text/html',\n",
       "  'language': None,\n",
       "  'base': 'https://feeds.megaphone.fm/stuffyoumissedinhistoryclass',\n",
       "  'value': \"Her story is often told in a sort of sloppy shorthand: She went to Los Angeles to become an actress, failed, and then became desperate. But that isn’t a really accurate picture of Peg Entwistle at all.&nbsp;<br><br><br><br><br><br><br><br>Learn more about advertising on the HowStuffWorks podcasts at <a href='http://www.howstuffworks.com/advertisers.htm'>www.howstuffworks.com/advertisers.htm</a><br><br>And to learn about your ad choices when listening to podcasts, visit <a href='https://www.howstuffworks.com/privacy.htm#ad-choices'>https://www.howstuffworks.com/privacy.htm#ad-choices</a>\"},\n",
       " 'published': 'Mon, 01 Oct 2018 14:10:11 -0000',\n",
       " 'published_parsed': time.struct_time(tm_year=2018, tm_mon=10, tm_mday=1, tm_hour=14, tm_min=10, tm_sec=11, tm_wday=0, tm_yday=274, tm_isdst=0),\n",
       " 'authors': [{'name': 'HowStuffWorks'}],\n",
       " 'author': 'HowStuffWorks',\n",
       " 'author_detail': {'name': 'HowStuffWorks'},\n",
       " 'itunes_title': 'Peg Entwistle, Ghost of Hollywood',\n",
       " 'itunes_episodetype': 'full',\n",
       " 'subtitle': '',\n",
       " 'subtitle_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'https://feeds.megaphone.fm/stuffyoumissedinhistoryclass',\n",
       "  'value': ''},\n",
       " 'content': [{'type': 'text/html',\n",
       "   'language': None,\n",
       "   'base': 'https://feeds.megaphone.fm/stuffyoumissedinhistoryclass',\n",
       "   'value': 'Her story is often told in a sort of sloppy shorthand: She went to Los Angeles to become an actress, failed, and then became desperate. But that isn’t a really accurate picture of Peg Entwistle at all.&nbsp;<br><br><br><br><br><br>'}],\n",
       " 'itunes_duration': '2378',\n",
       " 'id': 'https://feeds.megaphone.fm/5dbde55a-471e-11e8-8841-b3dd5f42775e',\n",
       " 'guidislink': True,\n",
       " 'link': 'https://feeds.megaphone.fm/5dbde55a-471e-11e8-8841-b3dd5f42775e',\n",
       " 'links': [{'length': '35412845',\n",
       "   'type': 'audio/mpeg',\n",
       "   'href': 'https://www.podtrac.com/pts/redirect.mp3/traffic.megaphone.fm/HSW3067373798.mp3',\n",
       "   'rel': 'enclosure'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Initialise the new dataframe\n",
    "episode_df = pd.DataFrame()\n",
    "\n",
    "# Load in each feeds file holding the episode descriptions (feeds_0 to feeds_22)\n",
    "for i in range(23):\n",
    "    floc = '/Users/Jay/AnacondaProjects/plutarch/get_episodes/preprocessed/'\n",
    "    with open(floc+'feeds_'+str(i)+'_1538437135.pkl','rb') as fid:\n",
    "        prog = pickle.load(fid)\n",
    "        print('Parsing file: '+'feeds_'+str(i)+'_1538437135.pkl'+' of 22')\n",
    "# Call in each list of episode descriptions and combine it with podcast_df listings\n",
    "    for j in range(len(prog)):\n",
    "        for k in range(len(prog[j])):\n",
    "            episode_df=episode_df.append({'description':prog[j][k][0],\n",
    "                                         'ep_title':prog[j][k][1],\n",
    "                                         'pod_title':prog[j][k][2]},\n",
    "                             ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_df['pod_title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc = '/Users/Jay/AnacondaProjects/plutarch/get_episodes/preprocessed/'\n",
    "fname = 'episode_df.csv'\n",
    "episode_df.to_csv(floc+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floc = '/Users/Jay/AnacondaProjects/plutarch/get_episodes/preprocessed/'\n",
    "fname = 'episode_df.csv'\n",
    "episode_df = pd.read_csv(floc+fname, encoding='utf-8')\n",
    "episode_df.drop_duplicates(['description'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
